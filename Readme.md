# ğŸ§± Multi-Client Azure Storage Automation with Terraform

## ğŸ“– Overview

This Terraform setup provisions **dedicated Azure Storage Accounts** for **multiple customers and environments** â€” ensuring:
- **Reusability:** same Terraform codebase works for all customers & environments  
- **Consistency:** standardized naming, tags, and configuration  
- **Scalability:** easily onboard new customers or environments  
- **Automation:** full lifecycle managed via `.bat` scripts & Service Principal authentication  

---

## ğŸ—‚ï¸ Repository Structure

```
â”œâ”€â”€ Modules/
â”‚   â””â”€â”€ storage_account/
â”‚       â”œâ”€â”€ main.tf               # Storage account resource logic
â”‚       â”œâ”€â”€ outputs.tf            # Structured module outputs
â”‚       â”œâ”€â”€ variables.tf          # Module-level variables
â”‚
â”œâ”€â”€ customers/
â”‚   â”œâ”€â”€ customerA/
â”‚   â”‚   â”œâ”€â”€ dev.tfvars
â”‚   â”‚   â”œâ”€â”€ test.tfvars
â”‚   â”‚   â”œâ”€â”€ stage.tfvars
â”‚   â”‚   â””â”€â”€ prod.tfvars
â”‚   â””â”€â”€ customerB/
â”‚       â”œâ”€â”€ dev.tfvars
â”‚       â””â”€â”€ prod.tfvars
â”‚
â”œâ”€â”€ main.tf                       # Root module â€” loops through storage accounts
â”œâ”€â”€ variables.tf                  # Required & optional input variables
â”œâ”€â”€ locals.tf                     # Naming conventions & tagging consistency
â”œâ”€â”€ outputs.tf                    # Aggregated summary output
â”‚
â”œâ”€â”€ .env                          # Environment variables for Service Principal (excluded from Git) 
â”‚
â”œâ”€â”€ tfplan.bat                      # Batch file for initialization and planning
â”œâ”€â”€ tfapply.bat                     # Batch file for deployment
â”œâ”€â”€ tfdestroy.bat                   # Batch file for destroying environments/resources
â”‚
â””â”€â”€ README.md                     # Documentation
```

---

## ğŸ” Authentication

This project uses a **Service Principal** for secure and non-interactive authentication.

Create a `.env` file (do **not** commit to Git):

```bash
ARM_TENANT_ID="xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
ARM_CLIENT_ID="xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
ARM_CLIENT_SECRET="your-client-secret"
```

Each batch file automatically reads this `.env` file to authenticate with Azure.

> âœ… Tip: Use separate Service Principals for prod vs. non-prod subscriptions for better security isolation.

---

## ğŸ§© Variable Structure

### Required Variables
| Variable | Description |
|-----------|--------------|
| `resource_group_name` | Target Resource Group |
| `location` | Azure region (e.g. `West Europe`) |
| `customer` | Customer name (used in naming and tags) |
| `environment` | Environment name (`dev`, `test`, `stage`, `prod`) |
| `subscription_id` | Azure Subscription ID |
| `storage_accounts` | Map of storage account configurations |

### Optional Variables
| Variable | Description | Default |
|-----------|--------------|----------|
| `additional_tags` | Extra tags for all resources | `{}` |
| `naming_prefix` | Prefix for naming convention | `"sa"` |
| `naming_pattern` | Override default naming | `""` |

---

## ğŸ—ï¸ Sample `.tfvars` (e.g., `customers/customerA/dev.tfvars`)

```hcl
resource_group_name = "rg-custA-dev"
location            = "West Europe"
customer            = "customerA"
environment         = "dev"
subscription_id     = "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"

storage_accounts = {
  data = {
    shortname        = "data"
    account_tier     = "Standard"
    replication_type = "LRS"
    enable_data_lake = true

    blob_containers = ["raw", "processed", "staging"]
    file_shares     = ["devshare"]
    tables          = ["metadata"]
    queues          = ["ingest-queue"]

    tags = {
      purpose = "data-platform"
    }
  }

  logs = {
    shortname        = "logs"
    account_tier     = "Standard"
    replication_type = "ZRS"

    blob_containers = ["logs"]

    tags = {
      purpose = "logging"
    }
  }
}
```

---

## ğŸ§® Naming Convention & Tag Consistency

Defined in `locals.tf`:

```hcl
naming_pattern = "${var.customer}${var.environment}${local.naming_prefix}"

base_tags = {
  project     = "multi-client-storage"
  managed_by  = "terraform"
  department  = "infrastructure"
}

effective_tags = merge(local.base_tags, {
  customer    = var.customer
  environment = var.environment
}, var.additional_tags)
```

All storage accounts automatically follow a uniform name and tag structure:
```
<customer>-<environment>-sa
```

---

## âš™ï¸ Automation Scripts

### ğŸ§© 1. `tfplan.bat`
Runs:
```bat
terraform init
terraform validate
terraform plan -var-file=./customers/<customer>/<env>.tfvars
```

Prompts for environment and customer. Exits automatically.

---

### ğŸš€ 2. `tfapply.bat`
Deploys resources:
```bat
terraform apply -var-file=./customers/<customer>/<env>.tfvars -auto-approve
```

---

### ğŸ’£ 3. `tfdestroy.bat`
Prompts to destroy either:
1. Entire environment
2. Specific resource

Example for destroying a single storage account:
```
module.storage_accounts["data"]
```

---

## ğŸ“¤ Outputs

Terraform prints a structured output like:

```hcl
storage_accounts_summary = {
  "data" = {
    name       = "customerA-dev-sa-data"
    id         = "/subscriptions/.../storageAccounts/customerA-dev-sa-data"
    location   = "westeurope"
    containers = ["raw", "processed", "staging"]
    file_shares = ["devshare"]
    queues      = ["ingest-queue"]
    tables      = ["metadata"]
  }
}
```

You can export it as JSON:
```bash
terraform output -json storage_accounts_summary > summary.json
```

---

## ğŸ”„ Lifecycle Example

| Step | Command | Description |
|------|----------|--------------|
| ğŸ§© Init/Plan | `init-plan-validate.bat` | Prepares Terraform and validates syntax |
| ğŸš€ Deploy | `apply.bat` | Deploys all resources for the selected customer/environment |
| ğŸ’£ Destroy | `destroy.bat` | Destroys environment or specific resource |
| ğŸ§¾ Output | `terraform output` | View structured resource summary |

---

## ğŸ§° Best Practices

âœ… Unique `.tfvars` per environment/customer  
âœ… `.env` local only, never commit  
âœ… Separate SPs for prod vs non-prod  
âœ… Isolated state files per environment/customer  
âœ… Run `terraform fmt` before commits  

---

## ğŸ Example Workflow

```bash
# Initialize, validate, and plan
init-plan-validate.bat

# Deploy
apply.bat

# Destroy a single storage account
destroy.bat
# Select option 2, then enter:
# module.storage_accounts["data"]
```

---

## ğŸ—ï¸ Conclusion

Fully automated, reusable, and consistent Terraform setup to manage Azure Storage Accounts across multiple customers and environments, ready for CI